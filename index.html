<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>AlignBot: Aligning VLM-powered Customized Task Planning with User Feedback Through Fine-Tuning for Household Robots</title>

    <script>
        var task_map = {
            "simple-object-manipulation": "simple_object_manipulation",
            "visual-goal-reaching": "visual_goal_reaching",
            "novel-concept-grounding": "novel_concept_grounding",
            "one-shot-video-imitation": "one_shot_video_imitation",
            "visual-constraint-satisfaction": "visual_constraint_satisfaction",
            "visual-reasoning": "visual_reasoning"
        };

        function updateDemoVideo(category) {
            var task = document.getElementById(category + "-menu-tasks").value;
            var inst = document.getElementById(category + "-menu-instances").value;

            console.log(task_map[category], task, inst)

            var video = document.getElementById(category + "-single-task-video");
            video.src = "assets/videos/demos/" +
                task_map[category] +
                "/" +
                task +
                "/" +
                inst +
                ".mp4";
            video.playbackRate = 2.0;
            video.play();
        }
    </script>

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="./static/css/academicons.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="./static/js/index.js"></script>

    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/bulma/0.9.3/css/bulma.min.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>

    <style>
        .tab-pane {
            display: none;
        }

        .tab-pane.active {
            display: block;
        }

        /* 隐藏Abstract之后的内容 */
        #hidden-content {
            display: none;
        }
    </style>

    <script>
        $(document).ready(function() {
            $(".tabs ul li a").click(function(e) {
                e.preventDefault();

                var targetTab = $(this).attr("href");

                $(".tabs ul li").removeClass("is-active");

                $(this).parent().addClass("is-active");

                $(".tab-content .tab-pane").removeClass("active");

                $(targetTab).addClass("active");
            });
        });
    </script>

</head>

<body>

    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column has-text-centered">
                        <h1 class="title is-1 publication-title"> AlignBot: Aligning VLM-powered Customized Task Planning with User Reminders Through Fine-Tuning for Household Robots</h1>
                        <h4 class="title is-4 conference-authors"><a target="_blank" href="https://2025.ieee-icra.org/"> Submitted to ICRA 2025</a></h4>
                        <div class="is-size-5 publication-authors">
                            <span class="author-block">
                                Zhaxizhuoma, Pengan Chen, Ziniu Wu, Jiawei Sun, Dong Wang, Peng Zhou
                                <br>
                                Nieqing Cao, Yan Ding, Bin Zhao, Xuelong Li
                            </span>
                        </div>
                    <div id="hidden-content" style="display: none;">
                        <div class="column has-text-centered">
                            <div class="publication-links">
                                <span class="link-block">
                                    <a target="_blank" href="https://arxiv.org/abs/2305.17590" class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="ai ai-arxiv"></i>
                                        </span>
                                        <span>ArXiv</span>
                                    </a>
                                </span>

                                <span class="link-block">
                                    <a target="_blank" href="https://github.com/yding25/GPT-Planner" class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fab fa-github"></i>
                                        </span>
                                        <span>Code</span>
                                    </a>

                                    <a target="_blank" href="./assets/datasets/COWP_dataset_12tasks_Final.xlsx" class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fas fa-database"></i>
                                        </span>
                                        <span>Dataset</span>
                                    </a>
                                    <a target="_blank" href="./assets/datasets/COWP_questionnaire.pdf" class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fas fa-file-pdf"></i>
                                        </span>
                                        <span>Questionnaire</span>
                                    </a>
                                    <a target="_blank" href="./assets/datasets/human_study_instruction.pdf" class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fas fa-file-pdf"></i>
                                        </span>
                                        <span>Instruction</span>
                                    </a>
                                </span>
                            </div>
                        </div>
                    </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <div id="hidden-content" style="display: none;">
    <section class="hero is-light is-small">
        <div class="hero-body">
            <div class="container">
                <div class="item item-sweep_without_exceeding" style="display: flex; justify-content: center; align-items: center;">
                    <video poster="" id="sweep_without_exceeding" autoplay controls muted loop style="width:70%;" playbackRate=2.0>
                        <source src="videos/demos/COWP_demo.mp4" type="video/mp4">
                    </video>
                </div>
            </div>
        </div>
    </section>
    </div>
    
    <section class="section">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column">
                    <h2 class="title is-3">Abstract</h2>
                    <div class="content has-text-justified">
                        <p style="font-size: 110%">
                            This paper presents AlignBot, a novel framework designed to optimize VLM-powered customized task planning for household robots by effectively aligning with user reminders.
                            In domestic settings, aligning task planning with user reminders poses significant challenges due to the limited quantity, diversity, and multimodal nature of the reminder itself.
                            To address these challenges, AlignBot employs a fine-tuned LLaVA-7B model, functioning as an adapter for GPT-4o.
                            This adapter model internalizes diverse forms of user reminders—such as personalized preferences, corrective guidance, and contextual assistance—into structured that prompt GPT-4o in generating customized task plans.
                            Additionally, AlignBot integrates a dynamic retrieval mechanism that selects relevant historical interactions as prompts for GPT-4o, further enhancing task planning accuracy.
                            To validate the effectiveness of AlignBot, experiments are conducted in a real-world household environment.
                            A multimodal dataset with 1,500 entries derived from volunteer reminder was used for training and evaluation.
                            The results demonstrate that AlignBot significantly improves customized task planning, outperforming existing LLM- and VLM-powered planners by interpreting and aligning with user reminders, achieving 86.8% success rate compared to the vanilla GPT-4o baseline at 21.6%, reflecting 65% improvement and over four times greater effectiveness.
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- 隐藏Abstract之后的内容 -->
    <div id="hidden-content">

    <!--Framework-->
    <section class="section">
        <div class="container is-max-widescreen">
            <div class="rows">
                <div class="rows is-centered ">
                    <div class="row is-full-width">
                        <h2 class="title is-3"><span class="dvima">Framework of COWP</span></h2>
                        <img src="./assets/images/Fig2.jpg" alt="Your image description" style="display: block; margin-left: auto; margin-right: auto; width: 80%;">
                        <br>
                        <span style="font-size: 110%">
                            An overview of COWP that includes the three key components of <span style="font-weight: bold">Task Planner</span> (provided as prior knowledge under closed-world assumption), <span style="font-weight: bold">Knowledge Acquirer</span>, and <span style="font-weight: bold">Plan Monitor</span>.
                        </span>
                        <br>
                        <span style="font-size: 110%">
                            <sup>&#8270;</sup> The green (dashed) loop represents a plan execution process where the robot does encounter no situation, or these situations have no impact on the robot's plan execution.
                        </span>
                        <br>
                        <span style="font-size: 110%">
                            <sup>&#8270;</sup> The orange loop is activated when the robot's current (closed-world) task planner is unable to develop a plan, which activates Knowledge Acquirer to augment the task planner with additional action effects utilizing common sense.
                        </span>
                    </div>
                </div>

            </div>
        </div>
    </section>

    <!--Prompt Design-->
    <section class="section">
        <div class="container is-max-widescreen">
            <div class="rows">
                <div class="rows is-centered ">
                    <div class="row is-full-width">
                        <h2 class="title is-3"><span class="dvima">Prompt Design for Plan Monitor and Knowledge Acquirer</span></h2>
                        <span style="font-size: 110%">
                            The realization of our plan monitor relies on repeatedly querying GPT-3 for each action using the following prompt.
                        </span>
                        <br>
                        <span style="font-size: 110%">
                            <span style="font-weight: bold">Prompt 1</span>: Is it suitable for a robot to [Perform-Action], if [Situation]?
                        </span>
                        <br>
                        <br>
                        <span style="font-size: 110%">
                            The following template is for querying an LLM for acquiring common sense about action effects.
                        </span>
                        <br>
                        <span style="font-size: 110%">
                            <span style="font-weight: bold">Prompt 2</span>: Is it suitable for a robot to [Perform-Action-with-Object]?
                        </span>
                        <br>
                        <span style="font-size: 110%">
                            <span style="font-weight: bold">Prompt 3</span>: There are some objects, such as [Object-1], [Object-2], ..., and [Object-N]. Which is the most suitable for [Current-Task], if [Situation]?
                        </span>
                        <br>
                        <span style="font-size: 110%">
                            <sup>&#8270;</sup> Please note that these prompts are zero-shot.
                        </span>
                    </div>
                </div>
            </div>
        </div>
    </section>
    
    <!--Situation Dataset-->
    <section class="section">
        <div class="container is-max-widescreen">
            <div class="rows">
                <div class="rows is-centered ">
                    <div class="row is-full-width">
                        <h2 class="title is-3"><span class="dvima">Situation Dataset</span></h2>
                        <span style="font-size: 110%">
                            Users can download both the MTurk questionnaire and the situation dataset at the top of the website. The dataset is provided as a CSV file comprising 12 separate sheets, each representing situations for a distinct task. The name of the task corresponds to the sheet name. Each sheet consists of five columns. 
                            <br>
                            <br>
                            The situations’ descriptions provided by the MTurkers are in Column A. Column B details the corresponding steps where the described situation occurs. Column C is the index of distinguishable situations, while Column D provides descriptions of these situations. Finally, Column E indicates the number of distinguishable situations.
                        </span>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!--Experiments-->
    <section class="section">
        <div class="container is-max-widescreen">
            <div class="rows">
                <div class="rows is-centered ">
                    <div class="row is-full-width">
                        <h2 class="title is-3"><span class="dvima">Experiments</span></h2>
                        <img src="./assets/images/Fig8.jpeg" alt="Your image description" style="display: block; margin-left: auto; margin-right: auto; width: 70%;">
                        <span style="font-size: 110%">
                            The task completion percentage of COWP (ours) and five baseline methods under 12 different tasks. The x-axis represents the task name, and the y-axis represents the task completion percentage. The task completion percentage for each value is an average of 150 trials. The tasks are sorted based on the performance of COWP, where the very left corresponds to its best performance.
                        </span>
                    </div>
                </div>


                <!-- Inserted Tabs Start -->
                <br>
                <span style="font-size: 110%">
                    Below shows the prompts and hyperparameters of baselines in the evaluation, where [] is a placeholder.
                </span>
                <br>
                <div class="tabs">
                    <ul>
                        <li class="is-active"><a href="#prompt_progprompt">Prompt for ProgPrompt</a></li>
                        <li><a href="#prompt_innermonologue">Prompt for Inner Monologue</a></li>
                        <li><a href="#hyperparameters_LMZSP">Hyperparameters used in LMZSP</a></li>
                    </ul>
                </div>

                <div class="tab-content">
                    <div class="tab-pane active" id="prompt_progprompt">
                        <pre><code>
from actions import walk &lt;obj&gt;, run &lt;obj&gt;, grab &lt;obj&gt;, switchon &lt;obj&gt;, switchoff &lt;obj&gt;, open &lt;obj&gt;, close &lt;obj&gt;, find &lt;obj&gt;, putin &lt;obj&gt; &lt;obj&gt;, fill &lt;obj&gt; &lt;obj&gt;, clean &lt;obj&gt;, wash &lt;obj&gt;
objects = ['wine', 'bucket', 'dish bowl', 'chips', 'sponge', 'snack', 'kitchencabinet', 'wastecontainer', 'cleaning bottle', 'drinking glass', 'kitchen cabinet', 'dish', 'coffee table', 'blender', 'dining table', 'mug', 'coffee maker', 'dehumidifier', 'air fryer', 'water filter', 'tea', 'dining', 'coffee filter', 'colander', 'orange juice', 'condiment bottle', 'watermelon juice', 'mat', 'closet', 'beer', garbagecan', 'cutlery knife', 'ice cream', 'sauce', 'table_1', 'oven tray', 'refrigerator', 'table cloth', 'steak', 'cupboard', 'wineglass', 'kitchen', 'cutting board', 'noodles', 'kitchen table', 'wooden chopstick', 'frying pan', 'cloth napkin', 'piano bench', 'toaster']
def put_the_wine_glass_in_the_kitchen_cabinet():
      # 0: walk to kitchen
      walk('kitchen')
      # 1: find wine glass
      find('wineglass')
      # 2: grab wine glass
      assert('close' to 'wineglass')
      else: find('wineglass')
      grab('wineglass')
      # 3: find kitchen cabinet
      find('kitchencabinet')
      # 4: open kitchen cabinet
      assert('close' to 'kitchencabinet' )
      else: find('kitchencabinet')
      assert('kitchencabinet' is 'closed' )
      else: close('kitchencabinet')
      open('kitchencabinet')
      # 5: put wine glass in kitchen cabinet
      assert('wineglass' in 'hands' )
      else: find('wineglass')
      else: grab('wineglass')
      assert('close' to 'kitchencabinet' )
      else: find('kitchencabinet')
      assert('kitchencabinet' is 'opened' )
      else: open('kitchencabinet')
      putin('wineglass', 'kitchencabinet')
      # 6: close kitchen cabinet
      assert('close' to 'kitchencabinet' )
      else: find('kitchencabinet')
      assert('kitchencabinet' is 'opened' )
      else: open('kitchencabinet')
      close('kitchencabinet')
      # 7: Done

from actions import walk &lt;obj&gt;, run &lt;obj&gt;, grab &lt;obj&gt;, switchon &lt;obj&gt;, switchoff &lt;obj&gt;, open &lt;obj&gt;, close &lt;obj&gt;, find &lt;obj&gt;, putin &lt;obj&gt; &lt;obj&gt;, fill &lt;obj&gt; &lt;obj&gt;, clean &lt;obj&gt;, wash &lt;obj&gt;
objects = ['wine', 'bucket', 'dish bowl', 'chips', 'sponge', 'snack', 'kitchencabinet', 'cleaning bottle', 'drinking glass', 'kitchen cabinet', 'dish', 'coffee table', 'blender', 'dining table', 'mug', 'coffee maker', 'dehumidifier', 'air fryer', 'water filter', 'tea', 'dining', 'coffee filter', 'colander', 'orange juice', 'condiment bottle', 'watermelon juice', 'mat', 'closet', 'beer', 'garbagecan_1', 'cutlery knife', 'ice cream', 'sauce', 'table_1', 'oven tray', 'refrigerator', 'table cloth', 'steak', 'cupboard', 'wineglass', 'kitchen', 'cutting board', 'noodles', 'kitchen table', 'wooden chopstick', 'frying pan', 'cloth napkin', 'garbagecan_2', 'piano bench', 'toaster']
def throw_away_the_lime, where garbagecan_1 is broken():
      # 0: find lime
      find('lime')
      # 1: grab lime
      assert('close' to 'lime')
      else: find('lime')
      grab('lime')
      # 2: find garbage can
      find('garbagecan_1')
      assert('broken' to 'garbagecan_1')
      else: find('garbagecan_2')
      # 3: open garbage can
      assert('close' to 'garbagecan_2' )
      else: find('garbagecan_2')
      assert('garbagecan_2' is 'closed' )
      else: close('garbagecan_2')
      open('garbagecan_2')
      # 4: put lime in garbage can
      assert('lime' in 'hands' )
      else: find('lime')
      else: grab('lime')
      assert('close' to 'garbagecan_2' )
      else: find('garbagecan_2')
      assert('garbagecan_2' is 'opened' )
      else: open('garbagecan_2')
      putin('lime', 'garbagecan_2')
      # 5: close garbage can
      assert('close' to 'garbagecan_2' )
      else: find('garbagecan_2')
      assert('garbagecan_2' is 'opened' )
      else: open('garbagecan_2')
      close('garbagecan_2)
      # 6: Done


from actions import walk &lt;obj&gt;, run &lt;obj&gt;, grab &lt;obj&gt;, switchon &lt;obj&gt;, switchoff &lt;obj&gt;, open &lt;obj&gt;, close &lt;obj&gt;, find &lt;obj&gt;, putin &lt;obj&gt; &lt;obj&gt;, fill &lt;obj&gt; &lt;obj&gt;, clean &lt;obj&gt;, wash &lt;obj&gt;
objects = ['wine', 'bucket', 'dish bowl', 'chips', 'sponge', 'snack', 'kitchencabinet', 'wastecontainer', 'cleaning bottle', 'drinking glass', 'kitchen cabinet', 'dish', 'coffee table', 'blender', 'dining table', 'mug', 'coffee maker', 'dehumidifier', 'air fryer', 'water filter', 'tea', 'dining', 'coffee filter', 'colander', 'orange juice', 'condiment bottle', 'watermelon juice', 'mat', 'closet', 'beer', garbagecan', 'cutlery knife', 'ice cream', 'sauce', 'table_1', 'oven tray', 'refrigerator', 'washingsponge', 'table cloth', 'steak', 'cupboard', 'wineglass', 'kitchen', 'cutting board', 'noodles', 'kitchen table', 'wooden chopstick', 'frying pan', 'cloth napkin', 'piano bench', 'toaster', 'dishwashingliquid', 'washingcloth']
def wash_mug, where washingsponge is missing():
      # 0: walk to kitchen
      walk('kitchen')
      # 1: find sink
      find('sink')
      # 2: turn on faucet
      find('faucet')
      assert('close' to 'faucet' )
      else: find('faucet')
      assert('faucet' is 'switchoff' )
      else: switchoff('faucet')
      switchon('faucet')
      # 3: put mug under water
      find('mug')
      assert('close' to 'mug')
      else: find('mug')
      grab('mug')
      find('sink')
      assert('mug' in 'hands' )
      else: find('mug')
      else: grab('mug')
      assert('close' to 'sink' )
      else: find('sink')
      putin('mug', 'sink')
      # 4: grab dishwashing liquid
      find('dishwashingliquid')
      assert('close' to 'dishwashingliquid')
      else: find('dishwashingliquid')
      grab('dishwashingliquid')
      # 5: put dishwashing liquid on mug
      find('sink')
      assert('dishwashingliquid' in 'hands' )
      else: find('dishwashingliquid')
      else: grab('dishwashingliquid')
      assert('close' to 'sink' )
      else: find('sink')
      putin('dishwashingliquid', 'sink')
      # 6: grab washingsponge
      find('washingsponge')
      assert('missing' to 'washingsponge')
      else: find('washingcloth')
      grab('washingcloth')
      # 7: start scrubbing mug
      find('sink')
      assert('washingcloth' in 'hands' )
      else: find('washingcloth')
      else: grab('washingcloth')
      assert('close' to 'sink' )
      else: find('sink')
      putin('washingcloth', 'sink')
      # 8: rinse mug off with water
      # 9: dry mug with towel
      # 10: Done

from actions import walk &lt;obj&gt;, run &lt;obj&gt;, grab &lt;obj&gt;, switchon &lt;obj&gt;, switchoff &lt;obj&gt;, open &lt;obj&gt;, close &lt;obj&gt;, find &lt;obj&gt;, putin&lt;obj&gt; &lt;obj&gt;, fill &lt;obj&gt; &lt;obj&gt;, clean &lt;obj&gt;, wash &lt;obj&gt;
objects = [objects in the environment]
def [task description], where [situation] ():
</code></pre>
                    </div>
                </div>

                <div class="tab-content">
                    <div class="tab-pane" id="prompt_innermonologue">
                        <pre><code>
Here are actions that can be executed by the robot: walk, run, grab, switch on, switch off, open, close, find, put, fill, clean, wash

Human: put the wine glass in the kitchen cabinet
Scene: ['orchid', 'sink', 'peach', 'mouse', 'oven tray', 'hanger', 'clothes pants', 'cupcake', 'power socket', 'bell pepper', 'slippers', 'toaster', 'closet', 'floor', 'pillow', 'door jamb', 'light switch', 'faucet', 'pie', 'bookshelf', 'cutlery fork', 'condiment shaker', 'bathroom counter', 'keyboard', 'cutlery knife', 'bananas', 'washing machine', 'box', 'ceiling', 'creamy buns', 'bed', 'crackers', 'bathroom', 'stove', 'paper', 'condiment bottle', 'lime', 'stove fan', 'washing sponge', 'deodorant', 'radio', 'kitchen', 'toilet', 'fridge', 'bedroom', 'dishwashing liquid', 'kitchen cabinet', 'remote control', 'folder', 'bar soap', 'bench', 'coffee pot', 'frying pan', 'curtains', 'desk', 'door', 'toothpaste', 'computer', 'painkillers', 'towel rack', 'cereal', 'wall', 'wall picture frame', 'bathtub', 'dish bowl', 'living room', 'cabinet', 'ceiling lamp', 'clothes pile', 'cpu screen', 'plum', 'photo frame', 'stall', 'table lamp', 'rug', 'toothbrush', 'coffee table', 'plate', 'water glass', 'chocolate syrup', 'window', 'bathroom cabinet', 'face cream', 'whipped cream', 'closet drawer', 'kitchen counter', 'tv', 'microwave', 'mug', 'perfume', 'salmon', 'candy bar', 'kitchen table', 'coffee maker', 'wall lamp', 'bread slice', 'towel', 'mouse mat', 'apple', 'cellphone', 'wall shelf', 'book', 'sofa', 'chips', 'wall phone', 'kitchen counter drawer', 'clothes shirt', 'candle', 'hair product', 'wine glass', 'garbage can', 'nightstand', 'clock', 'tv stand', 'chair']
Robot:
  0: walk to kitchen
  1: find wine glass
  2: grab wine glass
  3: find kitchen cabinet
  4: open kitchen cabinet
  5: put wine glass in kitchen cabinet
  6: close kitchen cabinet
  7: Done

Human: throw away the lime
Scene: ['garbage can_1 is broken', 'orchid', 'sink', 'peach', 'mouse', 'garbage can_1', 'oven tray', 'hanger', 'clothes pants', 'cupcake', 'power socket', 'bell pepper', 'slippers', 'toaster', 'closet', 'floor', 'pillow', 'door jamb', 'light switch', 'faucet', 'pie', 'bookshelf', 'cutlery fork', 'condiment shaker', 'bathroom counter', 'keyboard', 'cutlery knife', 'bananas', 'washing machine', 'box', 'ceiling', 'creamy buns', 'bed', 'crackers', 'bathroom', 'stove', 'paper', 'condiment bottle', 'lime', 'stove fan', 'washing sponge', 'deodorant', 'radio', 'kitchen', 'toilet', 'fridge', 'bedroom', 'dishwashing liquid', 'kitchen cabinet', 'remote control', 'folder', 'bar soap', 'bench', 'coffee pot', 'frying pan', 'curtains', 'desk', 'door', 'toothpaste', 'computer', 'painkillers', 'towel rack', 'cereal', 'wall', 'wall picture frame', 'bathtub', 'dish bowl', 'living room', 'cabinet', 'ceiling lamp', 'clothes pile', 'cpu screen', 'plum', 'photo frame', 'stall', 'table lamp', 'rug', 'toothbrush', 'coffee table', 'plate', 'water glass', 'chocolate syrup', 'window', 'bathroom cabinet', 'face cream', 'whipped cream', 'closet drawer', 'kitchen counter', 'tv', 'microwave', 'mug', 'perfume', 'salmon', 'candy bar', 'kitchen table', 'coffee maker', 'wall lamp', 'bread slice', 'towel', 'mouse mat', 'apple', 'cellphone', 'wall shelf', 'book', 'sofa', 'chips', 'wall phone', 'kitchen counter drawer', 'clothes shirt', 'candle', 'hair product', 'wine glass', 'garbage can_2', 'nightstand', 'clock', 'tv stand', 'chair']
Robot:
  0: find lime
  1: grab lime
  2: find garbage can_2
  3: open garbage can_2
  4: put lime in garbage can_2
  5: close garbage can_2
  6: Done

Human: wash mug
Scene: ['washing sponge is missing', 'orchid', 'sink', 'peach', 'mouse', 'oven tray', 'hanger', 'clothes pants', 'cupcake', 'power socket', 'bell pepper', 'slippers', 'toaster', 'closet', 'floor', 'pillow', 'door jamb', 'light switch', 'faucet', 'pie', 'bookshelf', 'cutlery fork', 'condiment shaker', 'bathroom counter', 'keyboard', 'cutlery knife', 'bananas', 'washing machine', 'box', 'ceiling', 'creamy buns', 'bed', 'crackers', 'bathroom', 'stove', 'paper', 'condiment bottle', 'lime', 'stove fan', 'washing sponge', 'deodorant', 'radio', 'kitchen', 'toilet', 'fridge', 'bedroom', 'dishwashing liquid', 'kitchen cabinet', 'remote control', 'folder', 'bar soap', 'bench', 'coffee pot', 'frying pan', 'curtains', 'desk', 'door', 'toothpaste', 'computer', 'painkillers', 'towel rack', 'cereal', 'wall', 'wall picture frame', 'bathtub', 'dish bowl', 'living room', 'cabinet', 'ceiling lamp', 'clothes pile', 'cpu screen', 'plum', 'photo frame', 'stall', 'table lamp', 'rug', 'toothbrush', 'coffee table', 'plate', 'water glass', 'chocolate syrup', 'window', 'bathroom cabinet', 'face cream', 'whipped cream', 'closet drawer', 'kitchen counter', 'tv', 'microwave', 'mug', 'perfume', 'salmon', 'candy bar', 'kitchen table', 'coffee maker', 'wall lamp', 'bread slice', 'towel', 'mouse mat', 'apple', 'cellphone', 'wall shelf', 'book', 'sofa', 'chips', 'wall phone', 'kitchen counter drawer', 'clothes shirt', 'candle', 'hair product', 'wine glass', 'garbage can', 'nightstand', 'clock', 'tv stand', 'chair']
Robot:
  0: walk to kitchen
  1: find sink
  2: switch on faucet
  3: put mug in sink
  4: grab dishwashing liquid
  5: put dishwashing liquid in sink
  6: grab washing cloth
  7: put washing cloth in sink
  8: wash mug
  8: Done


Scene: [situation, ojects in the environment]
Human: [task description]
Robot:
</code></pre>
                    </div>
                </div>

                <div class="tab-content">
                    <div class="tab-pane" id="hyperparameters_LMZSP">
                        <pre><code>
planning_lm_id = 'text-davinci-003'
translation_lm_id = 'stsb-roberta-large'
MAX_STEPS = 12  # maximum number of steps to be generated
CUTOFF_THRESHOLD = 0.5  # early stopping threshold based on matching score and likelihood score
P = 0.5  # hyperparameter for early stopping heuristic to detect whether Planning LM believes the plan is finished
BETA = 0.3  # weighting coefficient used to rank generated samples
sampling_params =
              {   "max_tokens": 256,
                  "temperature": 0.9,
                  "top_p": 0.9,
                  "n": 10,
                  "logprobs": 1,
                  "presence_penalty": 0.5,
                  "frequency_penalty": 0.3,
                  "stop": '\n'
              }
                        </code></pre>
                    </div>
                </div>
                        
            </div>
        </div>
    </section>

    <!--Conclusion-->
    <section class="section">
        <div class="container is-max-widescreen">
            <div class="rows">
                <div class="rows is-centered ">
                    <div class="row is-full-width">
                        <h2 class="title is-3"><span class="dvima">Conclusion</span></h2>

                        <p style="font-size: 110%">
                            In this paper, we develop a Large Language Model-based open-world task planning system for robots, called COWP, towards robust task planning and situation handling in open worlds.
                            The novelty of COWP points to the integration of a classical, knowledge-based task planning system, and a pretrained language model for commonsense knowledge acquisition.
                            The marriage of the two enables COWP to ground domain-independent commonsense knowledge to specific task planning problems.
                            To evaluate COWP systematically, we collected a situation dataset that includes 1085 situations in a dining domain.
                            Experimental results suggest that COWP performed better than existing task planners developed for closed-world and open-world scenarios.
                            We also provided a demonstration of COWP using a mobile manipulator working on delivery tasks, which provides a reference to COWP practitioners for real-world applications.
                        </p>

                    </div>
                </div>

            </div>
        </div>
    </section>


    <section class="section" id="BibTeX">
        <div class="container is-max-widescreen content">
            <h2 class="title">BibTeX</h2>
            <pre><code>
    @article{ding2023integrating,
      title={Integrating Action Knowledge and LLMs for Task Planning and Situation Handling in Open Worlds},
      author={Ding, Yan and Zhang, Xiaohan and Amiri, Saeid and Cao, Nieqing and Yang, Hao and Kaminski, Andy and Esselink, Chad and Zhang, Shiqi},
      journal={Autonomous Robots},
      year={2023}
    }
            </code></pre>
        </div>
    </section>

</div>

    <footer class="footer">
        <div class="container">
            <div class="columns is-centered">
                <div class="column">
                    <div class="content has-text-centered">
                        <p>
                            Website template borrowed from <a herf="https://vimalabs.github.io/"> VIMA, <a href="https://github.com/nerfies/nerfies.github.io">NeRFies</a> and <a href="https://github.com/cliport/cliport.github.io">CLIPort</a>.
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </footer>
</body>

</html>
